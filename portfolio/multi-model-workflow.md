# Multiâ€‘Model Workflow: Planner + Coder Architecture

This case study documents my experiments with a twoâ€‘model workflow:  
a **Planner model** for highâ€‘level reasoning and architecture, and a **Coder model** for implementation and debugging.

It was inspired by the idea that different models have different strengths â€” and that combining them might produce better results than relying on a single model.

The reality was more complicated, and far more educational.

---

## ğŸ§  The Setup

I used two local models running through Ollama:

- **Planner:** Llama 3.3 70B (architecture, reasoning, design)
- **Coder:** Qwen 2.5 Coder 32B (implementation, debugging, file edits)

My workflow configuration looked something like this:

- Planner handles architecture, design review, and highâ€‘level reasoning  
- Coder handles implementation, debugging, and file edits  
- Manual task switching  
- Verbose logging  
- Confirmâ€‘beforeâ€‘writing enabled  

The idea was simple:  
**Let the Planner think, let the Coder build.**

---

## ğŸ” What I Expected

I expected:

- Cleaner architecture  
- Fewer hallucinations  
- Better separation of concerns  
- More stable code generation  
- A smoother development flow  

And in some cases, I did get that.

But the real lessons came from what *didnâ€™t* work.

---

## âš ï¸ What Went Wrong (and Why)

### **1. The Planner hallucinated structure**
Large models sometimes â€œoverâ€‘plan,â€ inventing:

- Files that didnâ€™t exist  
- Components I never asked for  
- Entire architectures that didnâ€™t match the project  

### **2. The Coder followed the hallucinations**
The Coder model would try to implement whatever the Planner said â€” even if it was wrong.

This created a feedback loop of confusion.

### **3. Context drift became a real problem**
The more the Planner talked, the more it drifted from the original requirements.

### **4. Debugging became harder, not easier**
Instead of debugging code, I was debugging:

- Model disagreements  
- Conflicting instructions  
- Missing files  
- Incorrect assumptions  

### **5. Bigger models â‰  better results**
This was one of the biggest lessons.

Large models:

- Hallucinate more  
- Drift more  
- Overâ€‘generalize  
- Try to be â€œcreativeâ€ when I needed them to be precise  

---

## ğŸ§  What I Learned

### **1. Simplicity wins**
A single strong coder model with a tight prompt often outperformed the twoâ€‘model setup.

### **2. Human oversight is essential**
I had to:

- Correct the Planner  
- Override the Coder  
- Reâ€‘align the architecture  
- Reâ€‘prompt both models  

### **3. Multiâ€‘model workflows need strict constraints**
Without guardrails, the Planner becomes a novelist.

### **4. AI is a collaborator, not an autopilot**
The best results came when I treated the models as assistants, not decisionâ€‘makers.

---

## ğŸ› ï¸ What Iâ€™d Try Next

- Add a **verification model** to check Planner output  
- Add a **critic model** to evaluate code before execution  
- Use **smaller models** for more predictable behavior  
- Add a **debugger agent** to analyze runtime errors  
- Build a **prompt library** for consistent instructions  

---

## ğŸ“¦ Related Repository

This workflow was used while building:

https://github.com/LabNotesAI/ReactMongoAI
